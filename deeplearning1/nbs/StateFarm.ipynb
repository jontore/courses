{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(2), GPU number 0 is already in use.\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu2')\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from shutil import copyfile\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.utils.data_utils import get_file\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, BatchNormalization, Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important that the validation set not only contains a random selection of each class but also for each person, since there is multiple images of each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/statefarm/\"  \n",
    "#path = \"data/statefarm/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = path + 'models/'\n",
    "valid_path = path + 'valid/'\n",
    "\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file and create set of person and classes and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(valid_path): os.mkdir(valid_path) \n",
    "person_dict = {}\n",
    "with open(path + 'driver_imgs_list.csv') as f:\n",
    "    for line in f:\n",
    "        words = line.rstrip().split(',')\n",
    "        person_id = words[0]\n",
    "        label = words[1]\n",
    "        img = words[2]\n",
    "        if(person_id == 'subject'):\n",
    "            continue\n",
    "        \n",
    "        if person_id not in person_dict:\n",
    "            person_dict[person_id] = {}\n",
    "            person_dict[person_id][label] = [img]    \n",
    "        elif label not in person_dict[person_id]:\n",
    "            person_dict[person_id][label] = [img]\n",
    "        else: \n",
    "            person_dict[person_id][label].append(img)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p014', 'p041', 'p035', 'p012', 'p081'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_ppl = len(person_dict.keys())\n",
    "valid_index = int(round(0.8 * number_of_ppl))\n",
    "np.random.permutation(person_dict.keys())[valid_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_ppl = len(person_dict.keys())\n",
    "valid_index = int(round(0.8 * number_of_ppl))\n",
    "valid_ppl = np.random.permutation(person_dict.keys())[valid_index:]\n",
    "for p in valid_ppl:\n",
    "    for c in person_dict[p].keys():\n",
    "        g = person_dict[p][c]\n",
    "        random_order_images = np.random.permutation(g)\n",
    "        if not os.path.exists(valid_path + c): os.mkdir(valid_path + c) \n",
    "        for image in random_order_images:\n",
    "            os.rename((path + \"train/\" + c + \"/\" + image), (valid_path + c + \"/\" + image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sample set with 50 picture of training images and 10 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_path = path + 'sample/'\n",
    "sample_valid_path = sample_path + 'valid/'\n",
    "sample_train_path = sample_path + 'train/'\n",
    "number_of_ppl = len(person_dict.keys())\n",
    "classes = person_dict[person_dict.keys()[0]].keys()\n",
    "if not os.path.exists(sample_path): os.mkdir(sample_path) \n",
    "if not os.path.exists(sample_valid_path): os.mkdir(sample_valid_path)\n",
    "if not os.path.exists(sample_train_path): os.mkdir(sample_train_path) \n",
    "\n",
    "for c in classes:\n",
    "    if not os.path.exists(sample_train_path + c): os.mkdir(sample_train_path + c)\n",
    "    if not os.path.exists(sample_valid_path + c): os.mkdir(sample_valid_path + c) \n",
    "    try:\n",
    "        train_files_in_class = os.listdir(path + \"train/\" + c) \n",
    "        valid_files_in_cass = os.listdir(valid_path + c)\n",
    "        for i in range(140):\n",
    "            copyfile((path + \"train/\" + c + \"/\" + train_files_in_class[i]), (sample_train_path + c + \"/\" + train_files_in_class[i]))\n",
    "        for i in range(140, 180):\n",
    "            copyfile((path + \"valid/\" + c + \"/\" + valid_files_in_cass[i]), (sample_valid_path + c + \"/\" + valid_files_in_cass[i]))\n",
    "    except:\n",
    "        print(\"Something went wrong\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and fit to net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_size=224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data augmentation that was provided in course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17876 images belonging to 10 classes.\n",
      "Found 4548 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = gen_t.flow_from_directory(path + \"train\",\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              target_size=(224, 224),\n",
    "                                              shuffle=True);\n",
    "val_gen = gen_t.flow_from_directory(path + \"valid\",\n",
    "                                          batch_size=batch_size*2,\n",
    "                                          class_mode='categorical',\n",
    "                                          target_size=(224, 224),\n",
    "                                          shuffle=False)\n",
    "num_class=len(train_gen.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 150528)        0           input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 10)            1505290     flatten_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1505290\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(3, im_size, im_size))\n",
    "x = BatchNormalization(inputs)\n",
    "x = Flatten()(inputs)\n",
    "x = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=inputs, output=x)\n",
    "\n",
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n",
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1417/1417 [==============================] - 33s - loss: 14.5256 - acc: 0.0988 - val_loss: 14.5027 - val_acc: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ed5e85f50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, samples_per_epoch=train_gen.N, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_gen, nb_val_samples=val_gen.N, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n",
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417/1417 [==============================] - 33s - loss: 14.5256 - acc: 0.0988 - val_loss: 14.5027 - val_acc: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ee55c0150>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, samples_per_epoch=train_gen.N, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_gen, nb_val_samples=val_gen.N, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A super simple CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/ubuntu/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorma(None, 3, 224, 224)   6           input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, 222, 222)  1792        batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorma(None, 64, 222, 222)  128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 74, 74)    0           batchnormalization_14[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, 72, 72)    36928       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorma(None, 64, 72, 72)    128         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 64, 24, 24)    0           batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 36864)         0           block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 2000)          73730000    flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorma(None, 2000)          4000        dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2000)          0           batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 200)           400200      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorma(None, 200)           400         dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 200)           0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorma(None, 200)           400         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 10)            2010        batchnormalization_18[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 74175992\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Simple VGG inspired CNN\n",
    "inputs = Input(shape=(3, im_size, im_size))\n",
    "x = BatchNormalization(axis=1)(inputs)\n",
    "x = Convolution2D(64, 3, 3, activation='relu', name='block1_conv1')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D((3, 3), name='block1_pool')(x)\n",
    "x = Convolution2D(64, 3, 3, activation='relu', name='block1_conv2')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D((3, 3), name='block2_pool')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(2000, activation='relu')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "cnn = Model(input=inputs, output=x)\n",
    "\n",
    "cnn.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1400/1400 [==============================] - 28s - loss: 2.7057 - acc: 0.1800 - val_loss: 2.8272 - val_acc: 0.1300\n",
      "Epoch 2/2\n",
      "1400/1400 [==============================] - 26s - loss: 2.3547 - acc: 0.2514 - val_loss: 2.1821 - val_acc: 0.2075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dbeabea50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch=2\n",
    "cnn.fit_generator(train_gen, samples_per_epoch=train_gen.N, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_gen, nb_val_samples=val_gen.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "17876/17876 [==============================] - 325s - loss: 0.4455 - acc: 0.8544 - val_loss: 1.8283 - val_acc: 0.5438\n",
      "Epoch 2/4\n",
      "17876/17876 [==============================] - 324s - loss: 0.3791 - acc: 0.8804 - val_loss: 1.6575 - val_acc: 0.5697\n",
      "Epoch 3/4\n",
      "17876/17876 [==============================] - 324s - loss: 0.3373 - acc: 0.8944 - val_loss: 1.6138 - val_acc: 0.5671\n",
      "Epoch 4/4\n",
      "17876/17876 [==============================] - 324s - loss: 0.3008 - acc: 0.9064 - val_loss: 1.4905 - val_acc: 0.6088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dbe2317d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.lr=0.0001\n",
    "nb_epoch=4\n",
    "cnn.fit_generator(train_gen, samples_per_epoch=train_gen.N, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_gen, nb_val_samples=val_gen.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weigth_file_name =  model_path + 'simple-cnn-%d-one-epoch.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = 'data/statefarm/models/simple-cnn-%d-one-epoch.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b18a91a4d380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweigth_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         '''\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/home/ilan/minonda/conda-bld/work/h5py/h5f.c:1942)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = 'data/statefarm/models/simple-cnn-%d-one-epoch.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "cnn.load_weights(weigth_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn.save_weights(weigth_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c9', 'c8', 'c3', 'c2', 'c1', 'c0', 'c7', 'c6', 'c5', 'c4']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning pseudo labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels for the validation set and use that for the traning, notice that we don't use the validation lables, this would make our model biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pred = cnn.predict_generator(val_gen, val_gen.nb_sample)\n",
    "comb_pseudo = np.concatenate([da_trn_labels, val_pred])\n",
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/statefarm/test\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "print(path + \"test\")\n",
    "test_gen = ImageDataGenerator().flow_from_directory(path + \"test\",\n",
    "                                          batch_size=batch_size*2,\n",
    "                                          class_mode=None,\n",
    "                                          target_size=(224, 224),\n",
    "                                          shuffle=False)\n",
    "test_predictions = cnn.predict_generator(test_gen, test_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = sorted(train_gen.class_indices.keys())\n",
    "ids = list(map(lambda x: [re.search('.+\\/(.+\\.jpg)', x).group(1)], test_gen.filenames))\n",
    "subm = np.hstack((ids, test_predictions))\n",
    "class_str = ','.join(['img'] + classes)\n",
    "N = len(classes)\n",
    "format_str = ','.join(['%s'] + ['%s']*N)\n",
    "submission_file_name = 'statefarm.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt=format_str, header=class_str, comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloadable link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='statefarm.csv' target='_blank'>statefarm.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/statefarm.csv"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "submission_file_name = 'statefarm.csv'\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/statefarm/'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(train_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
